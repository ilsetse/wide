{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.775749585371992"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_search_queries = len(results)\n",
    "#size_of_query = -np.log(num_search_queries/total_entries_in_yr) # perform log transformation to work with larger numbers\n",
    "#size_of_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future work: use publishDate instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from finna_client import FinnaClient as fc\n",
    "from finna_client import FinnaSearchType as fst \n",
    "\n",
    "#################################\n",
    "\n",
    "#### USER INPUT / PARAMETERS ####\n",
    "search_query = \"EEG\"\n",
    "year = 2018              # SLIDER\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = fc() \n",
    "\n",
    "# input: int year\n",
    "# output: int total entries by year\n",
    "def get_total_entries_by_yr(year):\n",
    "    return fc.search(lookfor=\"\",\n",
    "           search_type=fst.Subject,\n",
    "           fields=[\"year\"],\n",
    "           filters=[(\"main_date_str:\"+str(year))],\n",
    "           page=1,\n",
    "           limit=100)['resultCount']\n",
    "\n",
    "\n",
    "def get_response(pg):\n",
    "    return fc.search(lookfor=search_query,\n",
    "           search_type=fst.Subject,\n",
    "           fields=[\"title\", \"buildings\", \"subjects\"],\n",
    "           facets=[\"author\"],\n",
    "           page=pg,\n",
    "           limit=100)\n",
    "\n",
    "\n",
    "def get_entries():\n",
    "    total_entries_in_yr = get_total_entries_by_yr(year)\n",
    "\n",
    "    total_pages = 0\n",
    "    results = []\n",
    "    while True:\n",
    "        try:\n",
    "            response = get_response(total_pages)\n",
    "            results += response['records']\n",
    "            total_pages += 1\n",
    "\n",
    "            # stopping condition\n",
    "            if len(results) >= response['resultCount']:\n",
    "                break     \n",
    "                \n",
    "        except:\n",
    "            print(\"num collected entries: \", len(results))\n",
    "            print(\"num expected entries: \", response['resultCount'])\n",
    "            break\n",
    "    \n",
    "    num_search_queries = len(results)\n",
    "            \n",
    "    data = json.dumps(results)\n",
    "    df = pd.read_json(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_num_entry_by_org_size_scores(df, year):\n",
    "    num_search_queries = len(df)\n",
    "    \n",
    "    buildings = []\n",
    "\n",
    "    for i in range(num_search_queries):\n",
    "        buildings.append(df['buildings'][i][0]['translated'])\n",
    "\n",
    "    unique_org = Counter(buildings).keys() # equals to list(set(words))\n",
    "    num_entries_by_org = Counter(buildings).values() # counts the elements' frequency\n",
    "    by_org_size_scores = [np.sqrt(x/num_search_queries)*100 for x in num_entries_by_org]\n",
    "\n",
    "    num_entry_by_org_size_scores = list(zip(unique_org, by_org_size_scores))\n",
    "\n",
    "    return num_entry_by_org_size_scores\n",
    "\n",
    "\n",
    "# co-occurrence matrix, work from 2000 - 2018\n",
    "def get_cooccurrence_matrix(df):\n",
    "    #df['subjects'].apply(pd.Series).stack().unique()\n",
    "    #list(set([a for b in df.val.tolist() for a in b]))\n",
    "\n",
    "    # toy example\n",
    "    # sample = [[[1]],[[1,1]],[[1,1,1]]]\n",
    "    # pd.DataFrame(sample).values.argmax()\n",
    "\n",
    "    #num_search_queries = len(df)\n",
    "    #idx_of_max_num_subjects = df['subjects'].values.argmax()\n",
    "    #len(df.loc[idx_of_max_num_subjects]['subjects'])\n",
    "\n",
    "    # to lowercase and strip ( . )\n",
    "    # toy example\n",
    "    # sample = [[[[\"Aa\"]]],[[[\"Bb\"]]],[[[\"Cc.\"],[\"Dd\"]]]]\n",
    "    # pd.DataFrame(sample).loc[2][0][0][0].lower().replace('.','')\n",
    "\n",
    "    subjects = [a[0].lower().replace('.','') for b in df['subjects'].tolist() for a in b]\n",
    "\n",
    "    unique_subject_list = list(set(subjects))\n",
    "    len(unique_subject_list)\n",
    "\n",
    "    subject_frequency = Counter(subjects).most_common() # counts the elements' frequency\n",
    "\n",
    "    # more data cleaning -> plural cases\n",
    "\n",
    "    # get the top commonly seen keywords occurring with the search query\n",
    "    TOP_VALUES = 10\n",
    "\n",
    "    key_subjects = []\n",
    "    for i in range(TOP_VALUES):\n",
    "        key_subjects.append(subject_frequency[i][0])\n",
    "\n",
    "    mat = np.zeros((len(df['subjects']), len(key_subjects)))\n",
    "\n",
    "\n",
    "    #subjects_by_publication\n",
    "    for x in range(len(df['subjects'])):\n",
    "        for y in range(len(key_subjects)):\n",
    "            for idx in range(len(df['subjects'][x])):\n",
    "                if df['subjects'][x][idx][0].lower().replace('.','') == key_subjects[y]:\n",
    "                    mat[x][y] += 1\n",
    "\n",
    "    co_mat = pd.DataFrame(mat.T.dot(mat), columns=key_subjects).astype(int)\n",
    "    np.fill_diagonal(co_mat.values, 0) # fill diagonal with 0\n",
    "\n",
    "    return co_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_entries()\n",
    "# get_num_entry_by_org_size_scores(df, year)\n",
    "comat = get_cooccurrence_matrix(df)\n",
    "comat.to_csv('comat.csv', sep='\\t', encoding='utf-8')\n",
    "comat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 115,  78,  58,  40,  40,  35,  33,  32,  26],\n",
       "       [115,   0,  31,  50,  18,  22,   8,   4,  16,  17],\n",
       "       [ 78,  31,   0,  36,  19,   9,   6,  11,  11,  10],\n",
       "       [ 58,  50,  36,   0,  17,   4,   0,   8,  12,  11],\n",
       "       [ 40,  18,  19,  17,   0,   2,   2,   4,   8,  10],\n",
       "       [ 40,  22,   9,   4,   2,   0,   5,   0,   1,   3],\n",
       "       [ 35,   8,   6,   0,   2,   5,   0,   4,   2,   2],\n",
       "       [ 33,   4,  11,   8,   4,   0,   4,   0,   8,   1],\n",
       "       [ 32,  16,  11,  12,   8,   1,   2,   8,   0,   5],\n",
       "       [ 26,  17,  10,  11,  10,   3,   2,   1,   5,   0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
